{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e759b533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy #数组相关\n",
    "import keras #神经网络相关\n",
    "from scipy import signal #预处理\n",
    "import os #环境\n",
    "import tensorflow as tf #神经网络框架\n",
    "from matplotlib import pyplot as plt #绘图\n",
    "from obspy import read #数据读取\n",
    "import sys, getopt #环境\n",
    "import time #计时\n",
    "import matplotlib #绘图\n",
    "from matplotlib.figure import Figure #绘图\n",
    "import h5py #读取文件 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb7f46db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_29 (Conv2D)          (None, 512, 512, 8)       400       \n",
      "                                                                 \n",
      " leaky_re_lu_48 (LeakyReLU)  (None, 512, 512, 8)       0         \n",
      "                                                                 \n",
      " max_pooling2d_29 (MaxPoolin  (None, 128, 128, 8)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 128, 128, 8)       1608      \n",
      "                                                                 \n",
      " leaky_re_lu_49 (LeakyReLU)  (None, 128, 128, 8)       0         \n",
      "                                                                 \n",
      " max_pooling2d_30 (MaxPoolin  (None, 32, 32, 8)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 32, 32, 12)        2412      \n",
      "                                                                 \n",
      " leaky_re_lu_50 (LeakyReLU)  (None, 32, 32, 12)        0         \n",
      "                                                                 \n",
      " max_pooling2d_31 (MaxPoolin  (None, 16, 16, 12)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_32 (Conv2D)          (None, 16, 16, 16)        4816      \n",
      "                                                                 \n",
      " leaky_re_lu_51 (LeakyReLU)  (None, 16, 16, 16)        0         \n",
      "                                                                 \n",
      " max_pooling2d_32 (MaxPoolin  (None, 8, 8, 16)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 8, 8, 16)          6416      \n",
      "                                                                 \n",
      " leaky_re_lu_52 (LeakyReLU)  (None, 8, 8, 16)          0         \n",
      "                                                                 \n",
      " max_pooling2d_33 (MaxPoolin  (None, 1, 1, 16)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 1, 1, 16)          0         \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 64)                1088      \n",
      "                                                                 \n",
      " leaky_re_lu_53 (LeakyReLU)  (None, 64)                0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,870\n",
      "Trainable params: 16,870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('mini2.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724d16cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#network 输入维度大小\n",
    "trace_win=512 \n",
    "time_win=512\n",
    "#network 训练时的采样率（不要修改，除非你知道这意味着什么）\n",
    "time_fre=100\n",
    "#带通滤波的值\n",
    "low_freq=20\n",
    "hign_freq=25\n",
    "#检测窗口的重叠率\n",
    "overlap=0.5\n",
    "#连续记录的路径（请保持所有记录具有相同的道数、采样率、文件长度等，以下所有代码不包括动态判断文件格式是否变化；如果需要可以修改读取函数并且在预处理函数中进行相应的修改）\n",
    "path=''\n",
    "#读取路径中符合条件的文件\n",
    "files = [name for name in os.listdir( path) if name.endswith('.mat')]\n",
    "#排序（注意，如果你的文件名按照一般排序后，时间不是连续的，那么文件的拼接会出现大问题，并且不会报错）\n",
    "files.sort()\n",
    "#文件长度\n",
    "file_lenth=len(files)\n",
    "#文件位置指针\n",
    "file_point=-1\n",
    "#时间位置指针\n",
    "time_point=0\n",
    "#结尾判断\n",
    "is_end=0\n",
    "#记录的道数（低于 512 时程序不会正常运行，如果需要，可以找我更改）\n",
    "channels=0\n",
    "#记录的采样率\n",
    "freq=0\n",
    "#记录的长度\n",
    "time_lenth=0\n",
    "#重采样比率\n",
    "time_scale=0\n",
    "#备用的参数\n",
    "count_fp=0\n",
    "#这个函数可以自动读取列表中的第一个文件，并且计算需要的参数（mat 格式）\n",
    "def get_parameters(path,files,time_fre):\n",
    "    mat = h5py.File(path+files[0])\n",
    "    matdata=mat['data']\n",
    "    freq=1/mat['dt'][0,0]\n",
    "    channels=matdata.shape[0]\n",
    "    times_lenth=mat['npts'][0,0]\n",
    "    time_scale=time_fre/freq\n",
    "    return freq,channels,times_lenth,time_scale\n",
    "#这个函数可以自动读取列表中的第一个文件，并且计算需要的参数（sgy 格式）\n",
    "def get_parameters(path, files, time_fre):\n",
    "    data=read(path+files[0])\n",
    "    freq=data[0].stats['sampling_rate']\n",
    "    channels=len(data)\n",
    "    times_lenth=data[0].stats['npts']\n",
    "    time_scale=time_fre / freq\n",
    "    return freq, channels, times_lenth, time_scale\n",
    "#这个函数可以自动读取列表中的第一个文件，并且计算需要的参数（dat 格式）\n",
    "def get_parameters(path,files,time_fre):\n",
    "    file = numpy.fromfile(path+files[0], dtype=\"f4\")\n",
    "    header = file[:10]\n",
    "    freq = int(header[6])\n",
    "    times_lenth = int(header[7])\n",
    "    channels = int(header[9])\n",
    "    time_scale=time_fre/freq\n",
    "    return freq,channels-1,times_lenth,time_scale\n",
    " \n",
    "freq,channels,time_lenth,time_scale=get_parameters(path,files,time_fre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852921b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgy2numpy(file):\n",
    "    global channels\n",
    "    temp=[]\n",
    "    temp_data=read(file)\n",
    "    for i in range(channels):\n",
    "        temp.append(temp_data[i].data)\n",
    "    return numpy.array(temp)\n",
    "def mat2numpy(file):\n",
    "    global channels,time_lenth\n",
    "    mat = h5py.File(file)\n",
    "    data=mat['data']\n",
    "    d=numpy.zeros_like(data)\n",
    "    for i in range(data.shape[0]-1):\n",
    "        d[i]=data[i+1]-data[i]\n",
    "    return d\n",
    "def dat2numpy(filename):\n",
    "    file = numpy.fromfile(filename, dtype=\"f4\")\n",
    "    header = file[:10]\n",
    "    fs = int(header[6])\n",
    "    npts = int(header[7])\n",
    "    dt = 1/fs\n",
    "    nch = int(header[9])\n",
    "    data = file[10:].reshape((nch,npts))\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85241a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_filter(data,fre_min,fre_max):\n",
    "    fmin=fre_min/(freq/2)\n",
    "    fmax=fre_max/(freq/2)\n",
    "    #print(fmin,fmax)\n",
    "    s1,s2=signal.butter(3,[fmin,fmax],'bandpass')\n",
    "    data_=signal.filtfilt(s1,s2,data) .copy()\n",
    "    return data_\n",
    "def data_S_L(data,freq):\n",
    "    #此处需要全局变量\n",
    "    short=int(0.2*freq)\n",
    "    long=int(freq)\n",
    "    #print('S_L:',short,long)\n",
    "    data_=data.copy()\n",
    "    for i in range(data.shape[0]):\n",
    "        data_[i,:]=S_L(data_[i,:],short,long).copy()\n",
    "    return data_[:,long: -short]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728609bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_input():\n",
    "    global file_point,low_freq,hign_freq,freq,files,path\n",
    "    #文件指针后移\n",
    "    file_point=file_point+1\n",
    "    print('file_input:'+str(file_point)+' '+files[file_point][21:31])\n",
    "    file_=path+files[file_point]\n",
    "    #调用文件读取函数，这里需要自行更改想要使用的函数\n",
    "    #这里没有异常检测函数，如果需要可以自己增加\n",
    "    data_=mat2numpy(file_)\n",
    "    return data_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e79fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init(begin):\n",
    "    #begin 指定开始的地方，例如，在程序运行到第 888 个文件时突然中断，可以将 begin 设为 888 接着开始\n",
    "    global file_point,low_freq,hign_freq,freq\n",
    "    global buffer_num\n",
    "    file_point=begin\n",
    "    #接收读取的数组\n",
    "    data_init=file_input().copy()\n",
    "    l1,l2=data_init.shape\n",
    "    buffer=numpy.zeros((l1,buffer_num*l2))\n",
    "    buffer[:,0:l2]=data_init.copy()\n",
    "    #塞满缓冲区\n",
    "    for i in range(buffer_num-1):\n",
    "        data_init=file_input().copy()\n",
    "        buffer[:,(i+1)*l2:(i+2)*l2]=data_init.copy()\n",
    "    return buffer\n",
    "def buffer_update(buffer):\n",
    "    global file_point,time_point,is_end,file_lenth\n",
    "    global buffer_num\n",
    "    #这里判断是否已经扫完所有的文件\n",
    "    if file_point+buffer_num > file_lenth:\n",
    "        is_end=1\n",
    "    else:\n",
    "        #将最后的一个文件提到最前方，这里是为了避免最后的部分出现目标信号，但是由于截断而漏检测\n",
    "        temp_each=int(buffer.shape[1]/buffer_num)\n",
    "        buffer[:,0:temp_each]=buffer[:,-temp_each:].copy()\n",
    "        #塞满后续的缓冲区\n",
    "        for i in range(buffer_num-1):\n",
    "            data_=file_input().copy()\n",
    "            buffer[:,(i+1)*temp_each:(i+2)*temp_each]=data_.copy()\n",
    "    return buffer\n",
    "def data_get(buffer):\n",
    "    global file_point,time_point,is_end,file_lenth,time_win,time_scale,trace_win,freq\n",
    "    global overlap\n",
    "    _overlap=1-overlap\n",
    "    #滤波\n",
    "    buffer=data_filter(buffer,low_freq,hign_freq)\n",
    "    #长短窗\n",
    "    buffer=data_S_L(buffer,freq)/5\n",
    "    #重采样\n",
    "    #这里的重采样方案可以保证即使输入通道少于 512 也能良好的运行，但是速度较慢\n",
    "    buffer=signal.resample(buffer,int(buffer.shape[1]*time_scale),axis=1)\n",
    "    buffer=signal.resample(buffer,512,axis=0).copy()\n",
    "#-------------------------- 更高效的方法是抽样：----------------------------#\n",
    "    '''\n",
    "    buffer_=data_filter(buffer,low_freq,hign_freq)\n",
    "    buffer_=data_f[numpy.arange(512)*channels//512]\n",
    "    buffer_=buffer_[:,(numpy.arange(buffer_.shape[1]*time_scale)*int(1/time_scale)).astype('int')]\n",
    "    buffer_=data_S_L(buffer_,freq/5).copy()/5\n",
    "    '''\n",
    "#------------------------ 或者可以采用叠加替换抽样提高检测能力 -----------------------------#\n",
    "    #print(buffer.shape)\n",
    "    win_num=int((buffer.shape[1]-overlap*time_win)//(_overlap*time_win)+1)\n",
    "    #print(win_num)\n",
    "    data_for_nn=numpy.zeros((win_num,time_win,trace_win))\n",
    "    #这里是切割一个个的检测窗口\n",
    "    for i in range(win_num-1):\n",
    "        data_for_nn[i,:,:]=buffer[:,int(i*time_win*_overlap):int(i*time_win*_overlap+time_win)]\n",
    "    data_for_nn[win_num-1,:,:]=buffer[:,(buffer.shape[1]-time_win):]\n",
    "    return data_for_nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2facaff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detec_flow(path,times=1e10,begin=0):\n",
    "    global model,model2,file_point,files\n",
    "    file_point=begin\n",
    "    #初始化\n",
    "    buffer=init(begin)\n",
    "    time_=numpy.zeros(min(times,len(files)))\n",
    "    t0=time.time()\n",
    "    print('')\n",
    "    #循环检测\n",
    "    while is_end==0 and file_point<times:\n",
    "        #可以添加用时记录\n",
    "        '''\n",
    "        if file_point%10==0:\n",
    "            print(data_each.shape)\n",
    "            print('time per file between',file_point-10,'-',file_point,':',(time.clock()-t0)/10)\n",
    "        '''\n",
    "        data_each=data_get(buffer)\n",
    "        #这里使用了两个模型，所以写了两遍\n",
    "        ans=data_detec(data_each,model)\n",
    "        ans2=data_detec(data_each,model2)\n",
    "        #ans2=model2.predict(data_each[:,:,:,0:1])\n",
    "        print(file_point)\n",
    "        is_true(ans,ans2,buffer,data_each)\n",
    "        time_[file_point]=time.time()-t0\n",
    "        #print('speed:',(time.time()-t0)/(file_point-begin),'cost:',(time.time()-t0))\n",
    "        buffer=buffer_update(buffer)\n",
    "    return time_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16527f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_true(ans,ans_,buffer,data_each):\n",
    "    global freq,count_fp,buffer2\n",
    "    global eq_files,full_files\n",
    "    print(buffer2.shape)\n",
    "    plt.imshow(buffer2,aspect='auto')\n",
    "    plt.xticks(numpy.arange(0,time_lenth*buffer_num*time_scale,time_lenth*time_scale),numpy.arange(0,int(time_lenth/freq*buffer_num),int(time_lenth/freq)))\n",
    "    plt.yticks([0,256,512],[0,256*4,512*4])\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Channel')\n",
    "    count_fp=count_fp+1\n",
    "    for i in range(len(ans)-1):\n",
    "        begin=i*time_win*(1-overlap)\n",
    "        #print(begin)\n",
    "        plt.plot([begin,begin+512],[512-i*7,512-i*7],color=colors[numpy.argmax(ans[i])])\n",
    "        plt.plot([begin,begin+512],[452-i*7,452-i*7],color=colors[numpy.argmax(ans_[i])])\n",
    "        #plt.plot([begin,begin+512/time_scale],[7000-i*100,7000-i*100],color=colors2[numpy.argmax(ans2[i])])\n",
    "    #plt.ylim(0,channels)\n",
    "    #plt.xlim(0,time_lenth*buffer_num-250)\n",
    "    plt.grid(axis='x',ls='--',color='white')\n",
    "    name=files[file_point-buffer_num+1][5:-8]\n",
    "    plt.title(name)\n",
    "    plt.savefig('./'+full_files+'/'+str(file_point-buffer_num+1)+'__'+name,dpi=100)\n",
    "    #print(ans)\n",
    "    if ans[:,1].max()>0.5 or ans_[:,1].max()>0.5:\n",
    "        plt.savefig('./'+eq_files+'/'+str(file_point-buffer_num+1)+'__'+name,dpi=100)\n",
    "        numpy.save('/home/lh21/DATB/APMusers/lvhao/qinghai_output/'+name+'__'+str(file_point-buffer_num+1),buffer2.astype('float16'))\n",
    "    plt.show()\n",
    "    return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3773343b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "#用到模型权重文件\n",
    "model2=keras.models.load_model('./mini2_qinghai.h5')\n",
    "model=keras.models.load_model('./mini2_for_qinghai.h5')\n",
    "#画图用到的颜色\n",
    "colors=['white','red']\n",
    "path='/home/lh21/DATA/Menyuan/Qingshizui/old/data/2022-01-09/'\n",
    "files = [name for name in os.listdir( path) if name.endswith('.dat')]\n",
    "files.sort()\n",
    "file_lenth=len(files)\n",
    "freq,channels,time_lenth,time_scale=get_parameters(path,files,time_fre)\n",
    " \n",
    "# 这是 istrue 函数里用到的，分别保存有地震信号和全部检测记录\n",
    "eq_files='./09eq_output'\n",
    "full_files='./09full_output'\n",
    "createFile(eq_files)\n",
    "createFile(full_files)\n",
    "buffer_num=5\n",
    "times=1e5\n",
    "overlap=0.5\n",
    "file_point=0\n",
    "print(overlap)\n",
    "is_end=0\n",
    " \n",
    "#这里开始检测\n",
    "detec_flow(path,times,begin=452)\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
